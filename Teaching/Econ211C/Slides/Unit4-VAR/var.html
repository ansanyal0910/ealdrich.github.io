<!DOCTYPE html>


<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Vector Autoregression &mdash; Econ 211C</title>
    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/styles.css" type="text/css" />
    <link rel="stylesheet" href="../_static/single.css" type="text/css" />
    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2016.03.29',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/common.js"></script>
    
    <script type="text/javascript" src="../_static/slides.js"></script>
    <script type="text/javascript" src="../_static/sync.js"></script>
    <script type="text/javascript" src="../_static/controller.js"></script>
    <script type="text/javascript" src="../_static/init.js"></script>
    
    
    <link rel="top" title="Econ 211C" href="../index.html" />
    <link rel="up" title="Vector Processes" href="../varProcesses.html" />
    <link rel="next" title="Autocovariances of Vector Processes" href="varACF.html" />
    <link rel="prev" title="Vector Processes" href="../varProcesses.html" /> 
  </head>
  <body>

<section
   id="slide_container"
   class='slides layout-regular'>


  
<article class="slide level-1" id="vector-autoregression">

<h1>Vector Autoregression</h1>





</article>
<article class="slide level-2" id="definition">

<h2>Definition</h2>

<p>A <span class="math">\(\smash{p}\)</span> th order vector autoregression generalizes a
scalar <span class="math">\(\smash{AR(p)}\)</span>:</p>
<div class="math">
\[\smash{\boldsymbol{Y}_{t} = \boldsymbol{c} +
\Phi_{1}\boldsymbol{Y}_{t-1} + \Phi_{2}\boldsymbol{Y}_{t-2} +
\ldots + + \Phi_{p}\boldsymbol{Y}_{t-p} +
\boldsymbol{\varepsilon}_{t}}.\]</div>
<ul class="simple">
<li><span class="math">\(\smash{Y_{t} = (Y_{1t},Y_{2t},\ldots,Y_{nt})^{'}}\)</span> is an
<span class="math">\(\smash{n \times 1}\)</span> vector of random variables.</li>
</ul>
<ul class="simple">
<li><span class="math">\(\smash{\boldsymbol{c} = (c_1,c_2,\ldots,c_n)^{'}}\)</span> is an
<span class="math">\(\smash{n \times 1}\)</span> vector of constants.</li>
</ul>
<ul class="simple">
<li><span class="math">\(\smash{\Phi_{j}}\)</span> is an <span class="math">\(\smash{n \times n}\)</span> matrix of
autoregressive coefficients for <span class="math">\(\smash{j = 1,\ldots,p}\)</span>.</li>
</ul>
<ul class="simple">
<li><span class="math">\(\smash{\boldsymbol{\varepsilon}_{t} =
(\varepsilon_{1t},\ldots, \varepsilon_{nt})^{'} }\)</span> is a vector white
noise process:</li>
</ul>
<div class="math">
\[\begin{split}\smash{E[\boldsymbol{\varepsilon}_{t}] = \boldsymbol{0}  \,\,\, \text{and}
\,\,\,
E[\boldsymbol{\varepsilon}_{t}\boldsymbol{\varepsilon}^{'}_{\tau}] =
\bigg\{\begin{array}{c} \Omega \hspace{10pt} t = \tau \\ 0
\hspace{10pt} \text{o/w} \\ \end{array}}.\end{split}\]</div>
<ul class="simple">
<li><span class="math">\(\smash{\boldsymbol{Y}_{t}}\)</span> is referred to as a
<span class="math">\(\smash{VAR(p)}\)</span>.</li>
</ul>




</article>
<article class="slide level-2" id="as">

<h2><span class="math">\(\smash{AR(p)}\)</span> as <span class="math">\(\smash{VAR(1)}\)</span></h2>

<p>Recall, an <span class="math">\(\smash{AR(p)}\)</span> can be written as a
<span class="math">\(\smash{VAR(1)}\)</span></p>
<div class="math">
\[\smash{\boldsymbol{Y}_{t} = \Phi \boldsymbol{Y}_{t-1} +
\boldsymbol{v}_{t}}\]</div>
<p>where</p>
<div class="math">
\[\begin{split}\smash{\boldsymbol{Y}_{t} = \left[\begin{array}{c} Y_{t} \\ \vdots
\\ Y_{t-p+1} \\ \end{array} \right], \hspace{10pt}
\Phi = \left[\begin{array}{ccccc} \phi_{1} &amp; \phi_{2}
&amp; \ldots &amp; \phi_{p-1} &amp; \phi_{p} \\ 1 &amp; 0 &amp; \ldots &amp; 0 &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\ 0 &amp; 0 &amp; \ldots
&amp; 1 &amp; 0 \\ \end{array} \right], \hspace{10pt}
\boldsymbol{v}_{t} = \left[\begin{array}{c}
\varepsilon_{t} \\ 0 \\ 0 \\ \vdots \\ 0 \\ \end{array}
\right]}\end{split}\]</div>
<div class="math">
\[\,\,\]</div>




</article>
<article class="slide level-2" id="lag-operator-notation">

<h2>Lag Operator Notation</h2>

<p>In lag operator notation,</p>
<div class="math">
\[\begin{split}\begin{align*}
\Phi(L) \boldsymbol{Y}_{t} &amp; = \left[I_{n} - \Phi_{1}L -
\Phi_{2}L^{2} - \ldots - \Phi_{p}L^{p}\right]\boldsymbol{Y}_{t}
\\
&amp; = \boldsymbol{c} + \boldsymbol{\varepsilon}_{t}.
\end{align*}\end{split}\]</div>
<ul class="simple">
<li><span class="math">\(\smash{\Phi(L)}\)</span> is a matrix where each component is a scalar
lag polynomial.</li>
</ul>




</article>
<article class="slide level-2" id="weak-stationarity">

<h2>Weak Stationarity</h2>

<p>The concept of weak stationarity is unchanged:
<span class="math">\(\smash{\boldsymbol{Y}_{t}}\)</span> is weakly stationary if</p>
<div class="math">
\[\smash{E[\boldsymbol{Y}_{t}] \,\,\, \text{and} \,\,\,
E[\boldsymbol{Y}_{t}\boldsymbol{Y}_{t-j}^{'}]}\]</div>
<p>are independent of <span class="math">\(\smash{t \,\, \forall \,\, j}\)</span></p>




</article>
<article class="slide level-2" id="mean">

<h2>Mean</h2>

<p>By weak stationarity,</p>
<div class="math">
\[\begin{split}\begin{align*}
E[\boldsymbol{Y}_{t}] &amp; = \boldsymbol{\mu} = \boldsymbol{c} +
\Phi_{1}\boldsymbol{\mu} + \ldots + \Phi_{p}\boldsymbol{\mu} \\
\implies \boldsymbol{\mu} &amp; = [I_{n} - \Phi_{1} - \ldots -
\Phi_{p}]^{-1}\boldsymbol{c}
\end{align*}\end{split}\]</div>
<p>Note that</p>
<div class="math">
\[\smash{\boldsymbol{\mu} = (\mu_{1},\mu_{2},\ldots,\mu_{n})^{'} \neq
(\mu,\mu,\ldots,\mu)^{'}}\]</div>
<p>Alternatively, we can re-express as a zero-mean process:</p>
<div class="math">
\[\smash{(\boldsymbol{Y}_{t} - \boldsymbol{\mu}) =
\Phi_{1}(\boldsymbol{Y}_{t-1} - \boldsymbol{\mu}) + \ldots +
\Phi_{p}(\boldsymbol{Y}_{t-p} - \boldsymbol{\mu}) +
\boldsymbol{\varepsilon}_{t}}.\]</div>




</article>
<article class="slide level-2" id="id1">

<h2><span class="math">\(\smash{VAR(p)}\)</span> as <span class="math">\(\smash{VAR(1)}\)</span></h2>

<p>We can write a <span class="math">\(\smash{VAR(p)}\)</span> as a <span class="math">\(\smash{VAR(1)}\)</span>:</p>
<div class="math">
\[\smash{\boldsymbol{\xi}_{t} = F\boldsymbol{\xi}_{t-1} +
\boldsymbol{v}_{t}}\]</div>
<p>where</p>
<div class="math">
\[\begin{split}\smash{\boldsymbol{\xi}_{t} = \left[\begin{array}{c}
\boldsymbol{Y}_{t} - \boldsymbol{\mu} \\ \boldsymbol{Y}_{t-1} -
\boldsymbol{\mu} \\ \vdots \\ \boldsymbol{Y}_{t-p+1} -
\boldsymbol{\mu} \\ \end{array} \right], \,\,\,
F = \left[\begin{array}{ccccc} \Phi_{1} &amp; \Phi_{2} &amp;\ldots&amp;
\Phi_{p-1} &amp; \Phi_{p} \\ I_{n} &amp; 0 &amp; 0 &amp; \ldots &amp; 0 \\ 0 &amp;
I_{n} &amp;\ldots &amp; 0 &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots
\\ 0 &amp; 0 &amp; \ldots &amp; I_{n} &amp; 0 \\
\end{array}\right], \,\,\,
\boldsymbol{v}_{t} = \left[\begin{array}{c}
\boldsymbol{\varepsilon}_{t} \\ 0 \\ 0 \\ \vdots \\ 0 \\
\end{array} \right]}.\end{split}\]</div>
<div class="math">
\[\,\,\]</div>




</article>
<article class="slide level-2" id="id2">

<h2><span class="math">\(\smash{VAR(p)}\)</span> as <span class="math">\(\smash{VAR(1)}\)</span></h2>

<p>Clearly,</p>
<div class="math">
\[\begin{split}\smash{E[\boldsymbol{v}_{t}\boldsymbol{v}_{\tau}^{'}] =
\bigg\{\begin{array}{c} Q \hspace{10pt} t = \tau \\ 0 \hspace{10pt}
\text{o/w} \\ \end{array}}\end{split}\]</div>
<p>where</p>
<div class="math">
\[\begin{split}\smash{Q = \left[\begin{array}{cccc} \Omega &amp; 0&amp; \ldots &amp; 0 \\ 0 &amp;
0 &amp; \ldots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp;
\ldots &amp; 0 \\ \end{array} \right]_{np \times np}}.\end{split}\]</div>
<div class="math">
\[\,\,\]</div>




</article>
<article class="slide level-2" id="recursive-iteration">

<h2>Recursive Iteration</h2>

<p>Recursively iterating on the <span class="math">\(\smash{VAR(1)}\)</span>:</p>
<div class="math">
\[\smash{\boldsymbol{\xi}_{t+s} =  \boldsymbol{v}_{t+s} +
F\boldsymbol{v}_{t+s-1}  + F^{2}\boldsymbol{v}_{t+s-2}  + \ldots +
F^{s-1}\boldsymbol{v}_{t+1}  + F^{s}\xi_{t}}.\]</div>
<p>Assuming <span class="math">\(\smash{F}\)</span> is nonsingular, it can be decomposed as</p>
<div class="math">
\[\smash{F = T \Lambda T^{-1}}.\]</div>
<ul class="simple">
<li><span class="math">\(\smash{\Lambda}\)</span> is a diagonal matrix comprised of the
<span class="math">\(\smash{np}\)</span> eigenvalues of <span class="math">\(\smash{F}\)</span>.</li>
</ul>
<ul class="simple">
<li><span class="math">\(\smash{T}\)</span> is a matrix of eigenvectors as columns.</li>
</ul>




</article>
<article class="slide level-2" id="id3">

<h2>Recursive Iteration</h2>

<p>Substituting the decomposition,</p>
<div class="math">
\[\begin{split}\begin{gather*}
F^2 = FF = (T \Lambda T^{-1})\,T \Lambda T^{-1} = T \Lambda^{2}
T^{-1} \\
\implies F^{s} =  T \Lambda^{s} T^{-1} \rightarrow 0 \,\,\,\,
\text{if} \,\,\,\, |\lambda_{k}| &lt; 1 \,\,\,\, \text{for} \,\,\,\, k
= 1, \ldots, np.
\end{gather*}\end{split}\]</div>
<p>If <span class="math">\(\smash{F^{s}\rightarrow 0}\)</span> as <span class="math">\(\smash{s\rightarrow
\infty}\)</span>,</p>
<ul class="simple">
<li>The effect of <span class="math">\(\smash{\boldsymbol{\varepsilon}_{t}}\)</span> on
<span class="math">\(\smash{\boldsymbol{\xi}_{t+s}}\)</span> dies out as
<span class="math">\(\smash{s\rightarrow \infty}\)</span>.</li>
</ul>
<ul class="simple">
<li><span class="math">\(\smash{\boldsymbol{\xi}_{t}}\)</span> (and hence
<span class="math">\(\smash{\boldsymbol{Y}_{t}}\)</span>) is stationary and causal.</li>
</ul>
<ul class="simple">
<li>Alternatively, <span class="math">\(\smash{\boldsymbol{Y}_{t}}\)</span> is stationary and
causal if the roots of <span class="math">\(\smash{[I_{n} - \Phi_{1}z -
\Phi_{2}z^{2} - \ldots - \Phi_{p}z^{p}]}\)</span> all lie outside the unit
circle.</li>
</ul>




</article>
<article class="slide level-2" id="vector-representation">

<h2>Vector <span class="math">\(\smash{MA(\infty)}\)</span> Representation</h2>

<p>If <span class="math">\(\smash{F^{s}\rightarrow 0}\)</span> as <span class="math">\(\smash{s\rightarrow
\infty}\)</span>, then</p>
<div class="math">
\[\smash{\boldsymbol{\xi}_{t+s} =  \boldsymbol{v}_{t+s} +
F\boldsymbol{v}_{t+s-1}  + F^{2}\boldsymbol{v}_{t+s-2} +
F^{3}\boldsymbol{v}_{t+s-3}  + \ldots}\]</div>
<p>which is a vector <span class="math">\(\smash{MA(\infty)}\)</span> process.</p>




</article>
<article class="slide level-2" id="id4">

<h2>Vector <span class="math">\(\smash{MA(\infty)}\)</span> Representation</h2>

<p>We can also write <span class="math">\(\smash{\boldsymbol{Y}_{t}}\)</span> alone as a vector
<span class="math">\(\smash{MA(\infty)}\)</span>. First, recognize</p>
<div class="math">
\[\begin{split}\begin{align*}
\boldsymbol{Y}_{t+s} &amp; = \boldsymbol{\mu} +
\boldsymbol{\varepsilon}_{t+s} + \Psi_{1}
\boldsymbol{\varepsilon}_{t+s-1} +  \Psi_{2}
\boldsymbol{\varepsilon}_{t+s-2} + \ldots + \Psi_{s-1}
\boldsymbol{\varepsilon}_{t+1} \\
&amp; \hspace{0.5in} + F_{11}^{(s)}(\boldsymbol{Y}_{t} -
\boldsymbol{\mu}) + F_{12}^{(s)}(\boldsymbol{Y}_{t-1} -
\boldsymbol{\mu}) + \ldots + F_{1p}^{(s)}(\boldsymbol{Y}_{t-p+1} -
\boldsymbol{\mu}).
\end{align*}\end{split}\]</div>
<ul class="simple">
<li><span class="math">\(\smash{\Psi_{j} = F_{11}^{(j)}}\)</span>.</li>
</ul>
<ul class="simple">
<li><span class="math">\(\smash{F_{1k}^{(j)}}\)</span> is comprised of rows 1 to
<span class="math">\(\smash{n}\)</span> and columns <span class="math">\(\smash{(k-1)n+1}\)</span> to
<span class="math">\(\smash{kn}\)</span> of matrix <span class="math">\(\smash{F^{j}}\)</span>.</li>
</ul>
<ul class="simple">
<li>Note that the matrices <span class="math">\(\smash{(F \times
F)[1:n,1:n]}\)</span> and <span class="math">\(\smash{F[1:n,1:n] \times
F[1:n,1:n]}\)</span> are not the same.</li>
</ul>




</article>
<article class="slide level-2" id="id5">

<h2>Vector <span class="math">\(\smash{MA(\infty)}\)</span> Representation</h2>

<p>Suppose all eigenvalues of <span class="math">\(\smash{F}\)</span> are inside the unit
circle.</p>
<ul class="simple">
<li>Then <span class="math">\(\smash{F^{s}\rightarrow 0}\)</span> as
<span class="math">\(\smash{s\rightarrow \infty}\)</span>.</li>
</ul>
<ul class="simple">
<li>This means <span class="math">\(\smash{F_{1k}^{(s)}\rightarrow 0}\)</span> as
<span class="math">\(\smash{s\rightarrow \infty}\)</span>.</li>
</ul>
<ul class="simple">
<li>In the limit</li>
</ul>
<div class="math">
\[\begin{split}\begin{align*}
\boldsymbol{Y}_{t+s} &amp; = \boldsymbol{\mu} +
\boldsymbol{\varepsilon}_{t+s} + \Psi_{1}
\boldsymbol{\varepsilon}_{t+s-1} +  \Psi_{2}
\boldsymbol{\varepsilon}_{t+s-2} + \ldots \\
&amp; = \boldsymbol{\mu} +
\Psi(L)\boldsymbol{\varepsilon}_{t+s}.
\end{align*}\end{split}\]</div>




</article>
<article class="slide level-2" id="inverse-of-lag-polynomial">

<h2>Inverse of <span class="math">\(\smash{MA(\infty)}\)</span> Lag Polynomial</h2>

<p>In this case <span class="math">\(\smash{\Psi(L) = \Phi(L)^{-1}}\)</span> or</p>
<div class="math">
\[\smash{[1 - \Phi_{1}L - \Phi_{2}L^{2} - \ldots - \Phi_{p}L^{p}][1 +
\Psi_{1}L + \Psi_{2}L^{2} + \ldots] = I_{n}}.\]</div>




</article>
<article class="slide level-2" id="representation-with-uncorrelated-noise">

<h2>Representation with Uncorrelated Noise</h2>

<p>We can always write a stationary and causal <span class="math">\(\smash{VAR(p)}\)</span> as
a vector <span class="math">\(\smash{MA(\infty)}\)</span> with a mutually uncorrelated white
noise vector.</p>
<ul class="simple">
<li>Define <span class="math">\(\smash{\boldsymbol{u}_{t} =
H\boldsymbol{\varepsilon}_{t}\,\,\,\,}\)</span> such that
<span class="math">\(\smash{\,\,\,\,H \Omega H^{'} = D}\)</span>.</li>
</ul>
<ul class="simple">
<li>Then</li>
</ul>
<div class="math">
\[\begin{split}\begin{align*}
\boldsymbol{Y}_{t} &amp; = \boldsymbol{\mu} +
H^{-1}H\boldsymbol{\varepsilon}_{t} +
\Psi_{1}(H^{-1}H)\boldsymbol{\varepsilon}_{t-1} + \ldots \\
&amp; = \boldsymbol{\mu} + J_{0}\boldsymbol{u}_{t} +
J_{1}\boldsymbol{u}_{t-1} + J_{2}\boldsymbol{u}_{t-2} + \ldots
\end{align*}\end{split}\]</div>
<p>where <span class="math">\(\smash{J_{s} = \Psi_{s}H^{-1}}\)</span>.</p>




</article>
<article class="slide level-2" id="id6">

<h2>Representation with Uncorrelated Noise</h2>

<ul class="simple">
<li>In this case the leading matrix <span class="math">\(\smash{J_{0} \neq I_{n}}\)</span>.</li>
</ul>
<ul class="simple">
<li>The noise vector is uncorrelated:</li>
</ul>
<div class="math">
\[\begin{split}\begin{align*}
E[\boldsymbol{u}_{t}\boldsymbol{u}_{t}^{'}] &amp; =
E[H\boldsymbol{\varepsilon}_{t} \boldsymbol{\varepsilon}_{t}^{'}
H^{'}] \\
&amp; = H E[\boldsymbol{\varepsilon}_{t}\boldsymbol{\varepsilon}_{t}]
H^{'} \\
&amp; = H \Omega H^{'} \\
&amp; = D.
\end{align*}\end{split}\]</div>




</article>

</section>

<section id="slide_notes">

</section>

  </body>
</html>