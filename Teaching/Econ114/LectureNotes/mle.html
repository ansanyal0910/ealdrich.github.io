


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Maximum Likelihood Estimation &mdash; Econ 114 - Advanced Quantitative Methods</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="Econ 114 - Advanced Quantitative Methods" href="index.html"/>
        <link rel="up" title="Distributions" href="distributions.html"/>
        <link rel="next" title="Resampling" href="resample.html"/>
        <link rel="prev" title="Heavy-Tailed Distributions" href="heavyDist.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        

        
          <a href="index.html" class="icon icon-home"> Econ 114
        

        
        </a>

        
          
          
        

        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

        
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
          
          
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="preliminaries.html">Preliminaries</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">Exploratory Data Analysis</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="distributions.html">Distributions</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="moments.html">Moments</a></li>
<li class="toctree-l2"><a class="reference internal" href="heavyDist.html">Heavy-Tailed Distributions</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="">Maximum Likelihood Estimation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#estimating-parameters-of-distributions">Estimating Parameters of Distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#joint-densities">Joint Densities</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id1">Joint Densities</a></li>
<li class="toctree-l3"><a class="reference internal" href="#independence">Independence</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Independence</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">Maximum Likelihood Estimation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#likelihood">Likelihood</a></li>
<li class="toctree-l3"><a class="reference internal" href="#likelihood-maximization">Likelihood Maximization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-likelihood">Log Likelihood</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">Log Likelihood</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mle-example">MLE Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">MLE Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">MLE Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">MLE Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mle-example-unknown">MLE Example: <span class="math">\(n=1\)</span>, Unknown <span class="math">\(\mu\)</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">MLE Example: <span class="math">\(n=1\)</span>, Unknown <span class="math">\(\mu\)</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#id9">MLE Example: <span class="math">\(n=1\)</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">MLE Example: <span class="math">\(n=1\)</span>, Unknown <span class="math">\(\mu\)</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">MLE Example: <span class="math">\(n=1\)</span>, Unknown <span class="math">\(\sigma\)</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#id12">MLE Example: <span class="math">\(n=1\)</span>, Unknown <span class="math">\(\sigma\)</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="#mle-accuracy">MLE Accuracy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fisher-information">Fisher Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id13">Fisher Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mle-central-limit-theorem">MLE Central Limit Theorem</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id14">MLE Central Limit Theorem</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mle-standard-errors">MLE Standard Errors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id15">MLE Standard Errors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mle-variance-example">MLE Variance Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id16">MLE Variance Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="resample.html">Resampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeSeries.html">Time Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian.html">Bayesian Methods</a></li>
</ul>

          
        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">Econ 114</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
          <li><a href="distributions.html">Distributions</a> &raquo;</li>
      
    <li>Maximum Likelihood Estimation</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/mle.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="maximum-likelihood-estimation">
<h1>Maximum Likelihood Estimation<a class="headerlink" href="#maximum-likelihood-estimation" title="Permalink to this headline">¶</a></h1>
<div class="section" id="estimating-parameters-of-distributions">
<h2>Estimating Parameters of Distributions<a class="headerlink" href="#estimating-parameters-of-distributions" title="Permalink to this headline">¶</a></h2>
<p>We almost never know the true distribution of a data sample.</p>
<ul class="to-build simple">
<li>We might hypothesize a family of distributions that capture broad
characteristics of the data (locations, scale and shape).</li>
</ul>
<ul class="to-build simple">
<li>However, there may be a set of one or more parameters of the
distribution that we don&#8217;t know.</li>
</ul>
<ul class="to-build simple">
<li>Typically we use the data to estimate the unknown parameters.</li>
</ul>
</div>
<div class="section" id="joint-densities">
<h2>Joint Densities<a class="headerlink" href="#joint-densities" title="Permalink to this headline">¶</a></h2>
<p>Suppose we have a collection of random variables <span class="math">\({\bf Y} =
(Y_1, \ldots, Y_n)'\)</span>.</p>
<ul class="to-build simple">
<li>We view a data sample of size <span class="math">\(n\)</span> as one realization of each
random variable: <span class="math">\({\bf y} = (y_1, \ldots, y_n)'\)</span>.</li>
</ul>
<ul class="to-build simple">
<li>The <em>joint cumulative density</em> of <span class="math">\({\bf Y}\)</span> is</li>
</ul>
<div class="to-build math">
\[\begin{split}F_{{\bf Y}}({\bf y}) &amp; = P(Y_1 \leq y_1, \ldots, Y_n \leq
y_n).\end{split}\]</div>
</div>
<div class="section" id="id1">
<h2>Joint Densities<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>The <em>joint probability density</em> of <span class="math">\({\bf Y}\)</span> is</li>
</ul>
<div class="math">
\[\begin{split}f_{{\bf Y}}({\bf y}) &amp; = \frac{\partial^n
F_{{\bf Y}}({\bf y})}{\partial Y_1 \ldots \partial Y_n}.\end{split}\]</div>
<p class="to-build">since</p>
<div class="to-build math">
\[\begin{split}F_{{\bf Y}}({\bf y})&amp; = \int_{-\infty}^{y_1}\ldots
\int_{-\infty}^{y_n} f_{{\bf Y}}({\bf a}) \,\, da_1 \ldots
da_n.\end{split}\]</div>
</div>
<div class="section" id="independence">
<h2>Independence<a class="headerlink" href="#independence" title="Permalink to this headline">¶</a></h2>
<p>When <span class="math">\(Y_1, \ldots, Y_n\)</span> are independent of each other and have
identical distributions:</p>
<ul class="to-build simple">
<li>We say that they are <em>independent and identically distributed</em>, or
i.i.d.</li>
</ul>
<ul class="to-build simple">
<li>When <span class="math">\(Y_1, \ldots, Y_n\)</span> are i.i.d., they have the same
marginal densities:</li>
</ul>
<div class="to-build math">
\[\begin{split}f_{Y_1}(y) &amp; = \ldots = f_{Y_n}(y).\end{split}\]</div>
</div>
<div class="section" id="id2">
<h2>Independence<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>Further, when <span class="math">\(Y_1, \ldots, Y_n\)</span> are i.i.d.</p>
<div class="math">
\[\begin{split}f_{{\bf Y}}({\bf y}) &amp; = f_{Y_1}(y_1) \cdot f_{Y_2}(y_2)
\cdots f_{Y_n}(y_n) = \prod_{i=1}^n f_{Y_i}(y_i).\end{split}\]</div>
<ul class="to-build simple">
<li>This is analogous to the computation of joint probabilities.</li>
</ul>
<ul class="to-build simple">
<li>For independent events <span class="math">\(A\)</span>, <span class="math">\(B\)</span> and <span class="math">\(C\)</span>,</li>
</ul>
<div class="to-build math">
\[\begin{split}P(A \cap B \cap C) &amp; = P(A)P(B)P(C).\end{split}\]</div>
</div>
<div class="section" id="id3">
<h2>Maximum Likelihood Estimation<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>One of the most important and powerful methods of parameter estimation
is <em>maximum likelihood estimation</em>.  It requires</p>
<ul class="to-build simple">
<li>A data sample: <span class="math">\({\bf y} = (y_1, \ldots, y_n)'\)</span>.</li>
</ul>
<ul class="to-build simple">
<li>A joint probability density:</li>
</ul>
<div class="to-build math">
\[\begin{split}f_{{\bf Y}}({\bf y}|{\bf \theta}) &amp; = \prod_{i=1}^n
f_{Y_i}(y_i|{\bf \theta}).\end{split}\]</div>
<p class="to-build">where <span class="math">\({\bf \theta}\)</span> is a vector of parameters.</p>
</div>
<div class="section" id="likelihood">
<h2>Likelihood<a class="headerlink" href="#likelihood" title="Permalink to this headline">¶</a></h2>
<p><span class="math">\(f_{{\bf Y}}({\bf y}|{\bf \theta})\)</span> is loosely interpreted
as the probability of observing data sample <span class="math">\({\bf y}\)</span>, given a
functional form for the density of <span class="math">\(Y_1, \ldots, Y_n\)</span> and given
a set of parameters <span class="math">\({\bf \theta}\)</span>.</p>
<ul class="to-build simple">
<li>We can reverse the notion and think of <span class="math">\({\bf y}\)</span> as being
fixed and <span class="math">\({\bf \theta}\)</span> some unknown variable.</li>
</ul>
<ul class="to-build simple">
<li>In this case we write <span class="math">\(\mathcal{L}({\bf \theta}|{\bf y}) =
f_{{\bf Y}}({\bf y}|{\bf \theta})\)</span>.</li>
</ul>
<ul class="to-build simple">
<li>We refer to <span class="math">\(\mathcal{L}({\bf \theta}|{\bf y})\)</span> as the
likelihood.</li>
</ul>
<ul class="to-build simple">
<li>Fixing <span class="math">\({\bf y}\)</span>, maximum likelihood estimation chooses the
value of <span class="math">\({\bf \theta}\)</span> that maximizes
<span class="math">\(\mathcal{L}({\bf \theta}|{\bf y}) =
f_{{\bf Y}}({\bf y}|{\bf \theta})\)</span>.</li>
</ul>
</div>
<div class="section" id="likelihood-maximization">
<h2>Likelihood Maximization<a class="headerlink" href="#likelihood-maximization" title="Permalink to this headline">¶</a></h2>
<p>Given <span class="math">\({\bf \theta} = (\theta_1, \ldots, \theta_p)'\)</span>, we
maximize <span class="math">\(\mathcal{L}({\bf \theta}|{\bf y})\)</span> by</p>
<ul class="to-build simple">
<li>Differentiating with respect to each <span class="math">\(\theta_i\)</span>, <span class="math">\(i = 1,
\ldots, p\)</span>.</li>
</ul>
<ul class="to-build simple">
<li>Setting the resulting derivatives equal to zero.</li>
</ul>
<ul class="to-build simple">
<li>Solving for the values <span class="math">\(\hat{\theta}_i\)</span>, <span class="math">\(i = 1, \ldots,
p\)</span>, that make all of the derivatives zero.</li>
</ul>
</div>
<div class="section" id="log-likelihood">
<h2>Log Likelihood<a class="headerlink" href="#log-likelihood" title="Permalink to this headline">¶</a></h2>
<p>It is often easier to work with the logarithm of the likelihood
function.</p>
<ul class="to-build simple">
<li>By the properties of logarithms</li>
</ul>
<div class="to-build math">
\[\begin{split}\ell({\bf \theta}|{\bf y}) &amp; =
\log\left(\mathcal{L}({\bf \theta}|{\bf y})\right)\end{split}\]</div>
<div class="to-build math">
\[\begin{split}\qquad \enspace &amp; = \log \left(f_{{\bf Y}}({\bf y}|{\bf \theta})\right)\end{split}\]</div>
<div class="to-build math">
\[\begin{split}\qquad \enspace \qquad &amp; = \log \left(\prod_{i=1}^n
f_{Y_i}(y_i|{\bf \theta})\right)\end{split}\]</div>
<div class="to-build math">
\[\begin{split}\qquad \qquad &amp; = \sum_{i=1}^n \log\left(f_{Y_i}(y_i|{\bf
\theta})\right).\end{split}\]</div>
</div>
<div class="section" id="id4">
<h2>Log Likelihood<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Maximizing <span class="math">\(\ell({\bf \theta}|{\bf y})\)</span> is the same as
maximizing <span class="math">\(\mathcal{L}({\bf \theta}|{\bf y})\)</span> since
<span class="math">\(\log\)</span> is a monotonic transformation.</li>
</ul>
<ul class="to-build simple">
<li>A derivative of <span class="math">\(\mathcal{L}\)</span> will involve many chain-rule
products, whereas a derivative of <span class="math">\(\ell\)</span> will simply be a sum
of derivatives.</li>
</ul>
</div>
<div class="section" id="mle-example">
<h2>MLE Example<a class="headerlink" href="#mle-example" title="Permalink to this headline">¶</a></h2>
<p>Suppose we have a dataset <span class="math">\({\bf y} = (y_1, \ldots, y_n)\)</span>,
where <span class="math">\(Y_1, \ldots, Y_n \stackrel{i.i.d.}{\sim} \mathcal{N}(\mu,
\sigma^2)\)</span>.</p>
<ul class="to-build simple">
<li>We will assume <span class="math">\(\mu\)</span> is <em>unknown</em> and <span class="math">\(\sigma\)</span> is
<em>known</em>.</li>
</ul>
<ul class="to-build simple">
<li>So, <span class="math">\({\bf \theta} = \mu\)</span> (it is a single value, rather than
a vector).</li>
</ul>
</div>
<div class="section" id="id5">
<h2>MLE Example<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>The likelihood is</li>
</ul>
<div class="math">
\[\begin{split}\mathcal{L}(\mu|{\bf y}) &amp; = f_{{\bf Y}}({\bf y}|\mu) \qquad \qquad
\qquad \qquad \qquad \qquad\end{split}\]</div>
<div class="to-build math">
\[\begin{split}&amp; = \prod_{i=1}^n f_{Y_i}(y_i|\mu) \qquad \qquad \qquad \qquad\end{split}\]</div>
<div class="to-build math">
\[\begin{split}\quad &amp; = \prod_{i=1}^n \frac{1}{\sqrt{2\pi \sigma^2}} \exp
\left\{-\frac{1}{2} \frac{(y_i - \mu)^2}{\sigma^2} \right\}\end{split}\]</div>
<div class="to-build math">
\[\begin{split}\qquad \enspace &amp; = \frac{1}{(2\pi \sigma^2)^{n/2}} \exp
\left\{-\frac{1}{2 \sigma^2} \sum_{i=1}^n (y_i - \mu)^2 \right\}.\end{split}\]</div>
</div>
<div class="section" id="id6">
<h2>MLE Example<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>The log likelihood is</p>
<div class="math">
\[\begin{split}\ell(\mu|{\bf y}) &amp; = -\frac{n}{2} \log(2\pi) - \frac{n}{2}
\log(\sigma^2) - \frac{1}{2 \sigma^2} \sum_{i=1}^n (y_i - \mu)^2.\end{split}\]</div>
</div>
<div class="section" id="id7">
<h2>MLE Example<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>The MLE, <span class="math">\(\hat{\mu}\)</span>, is the value that sets <span class="math">\(\frac{d}{d
\mu} \ell(\mu|{\bf y}) = 0\)</span>:</li>
</ul>
<div class="to-build math">
\[\frac{d}{d \mu} \ell(\mu|{\bf y}) \bigg|_{\hat{\mu}} =
\frac{1}{\sigma^2} \sum_{i=1}^n (y_i - \hat{\mu}) = 0\]</div>
<div class="to-build math">
\[\Rightarrow \sum_{i=1}^n (y_i - \hat{\mu}) = 0\]</div>
<div class="to-build math">
\[\Rightarrow \sum_{i=1}^n \hat{\mu} = \sum_{i=1}^n y_i\]</div>
<div class="to-build math">
\[\Rightarrow \hat{\mu} = \bar{y} = \frac{1}{n} \sum_{i=1}^n y_i.\]</div>
</div>
<div class="section" id="mle-example-unknown">
<h2>MLE Example: <span class="math">\(n=1\)</span>, Unknown <span class="math">\(\mu\)</span><a class="headerlink" href="#mle-example-unknown" title="Permalink to this headline">¶</a></h2>
<p>Suppose we have only one observation: <span class="math">\(y_1\)</span>.</p>
<ul class="to-build simple">
<li>If we specialize the previous result:</li>
</ul>
<div class="to-build math">
\[\begin{split}\hat{\mu} &amp; = y_1.\end{split}\]</div>
<ul class="to-build simple">
<li>The density <span class="math">\(f_{Y_1}(y_1|\mu)\)</span> gives the probability of
observing some data value <span class="math">\(y_1\)</span>, conditional on some <em>known</em>
parameter <span class="math">\(\mu\)</span>.</li>
</ul>
<ul class="to-build simple">
<li>This is a normal distribution with mean <span class="math">\(\mu\)</span> and variance
<span class="math">\(\sigma^2\)</span>.</li>
</ul>
</div>
<div class="section" id="id8">
<h2>MLE Example: <span class="math">\(n=1\)</span>, Unknown <span class="math">\(\mu\)</span><a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>The likelihood <span class="math">\(\mathcal{L}(\mu|y_1)\)</span> gives the probability of
<span class="math">\(\mu\)</span>, conditional on some observed data value <span class="math">\(y_1\)</span>.</li>
</ul>
<ul class="to-build simple">
<li>This is a normal distribution with mean <span class="math">\(y_1\)</span> and variance
<span class="math">\(\sigma^2\)</span>.</li>
</ul>
</div>
<div class="section" id="id9">
<h2>MLE Example: <span class="math">\(n=1\)</span><a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><a class="reference internal image-reference" href="_images/densExample.png"><img alt="_images/densExample.png" class="align-center" src="_images/densExample.png" style="width: 7.5in;" /></a>
</div></blockquote>
</div>
<div class="section" id="id10">
<h2>MLE Example: <span class="math">\(n=1\)</span>, Unknown <span class="math">\(\mu\)</span><a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><a class="reference internal image-reference" href="_images/likeExample.png"><img alt="_images/likeExample.png" class="align-center" src="_images/likeExample.png" style="width: 5in;" /></a>
</div></blockquote>
</div>
<div class="section" id="id11">
<h2>MLE Example: <span class="math">\(n=1\)</span>, Unknown <span class="math">\(\sigma\)</span><a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<p>Let&#8217;s continue with the assumption of one data observation, <span class="math">\(y_1\)</span>.</p>
<ul class="to-build simple">
<li>If <span class="math">\(\mu\)</span> is known but <span class="math">\(\sigma\)</span> is unknown, the density
of the data, <span class="math">\(y_1\)</span>, is still normal.</li>
</ul>
<ul class="to-build simple">
<li>However, the likelihood is</li>
</ul>
<div class="to-build math">
\[\mathcal{L}(\sigma^2|y_1) = \frac{\alpha}{\sigma^2}
\exp\left\{-\frac{\beta}{\sigma^2}\right\}\]</div>
<div class="to-build math">
\[\alpha = \frac{1}{\sqrt{2\pi}}, \qquad \beta =
\frac{(y_1-\mu)^2}{2}.\]</div>
<ul class="to-build simple">
<li>The likelihood for <span class="math">\(\sigma^2\)</span> is <em>not</em> normal, but <em>inverse
gamma</em>.</li>
</ul>
</div>
<div class="section" id="id12">
<h2>MLE Example: <span class="math">\(n=1\)</span>, Unknown <span class="math">\(\sigma\)</span><a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><a class="reference internal image-reference" href="_images/likeExample2.png"><img alt="_images/likeExample2.png" class="align-center" src="_images/likeExample2.png" style="width: 5in;" /></a>
</div></blockquote>
</div>
<div class="section" id="mle-accuracy">
<h2>MLE Accuracy<a class="headerlink" href="#mle-accuracy" title="Permalink to this headline">¶</a></h2>
<p>Maximum likelihood estimation results in estimates of true unknown
parameters.</p>
<ul class="to-build simple">
<li>What is the probability that our estimates are identical to the true
population parameters?</li>
</ul>
<ul class="to-build simple">
<li>Our estimates are imprecise and contain error.</li>
</ul>
<ul class="to-build simple">
<li>We would like to quantify the precision of our estimates with
standard errors.</li>
</ul>
<ul class="to-build simple">
<li>We will use the <em>Fisher Information</em> to compute standard errors.</li>
</ul>
</div>
<div class="section" id="fisher-information">
<h2>Fisher Information<a class="headerlink" href="#fisher-information" title="Permalink to this headline">¶</a></h2>
<p>Suppose our likelihood is a function of a single parameter,
<span class="math">\(\theta\)</span>: <span class="math">\(\mathcal{L}(\theta|{\bf y})\)</span>.</p>
<ul class="to-build simple">
<li>The Fisher Information is</li>
</ul>
<div class="to-build math">
\[\begin{split}\mathcal{I}(\theta) &amp; = - E\left[\frac{d^2}{d \theta^2}
\ell(\theta|{\bf y}) \right].\end{split}\]</div>
<ul class="to-build simple">
<li>The observed Fisher Information is</li>
</ul>
<div class="to-build math">
\[\begin{split}\widetilde{\mathcal{I}}(\theta) &amp; = - \frac{d^2}{d \theta^2}
\ell(\theta|{\bf y}).\end{split}\]</div>
</div>
<div class="section" id="id13">
<h2>Fisher Information<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Observed Fisher Information does not take an expectation, which may
be difficult to compute.</li>
</ul>
<ul class="to-build simple">
<li>Since <span class="math">\(\ell(\theta|{\bf y})\)</span> is often a sum of many terms,
<span class="math">\(\widetilde{\mathcal{I}}(\theta)\)</span> will converge to
<span class="math">\(\mathcal{I}(\theta)\)</span> for large samples.</li>
</ul>
</div>
<div class="section" id="mle-central-limit-theorem">
<h2>MLE Central Limit Theorem<a class="headerlink" href="#mle-central-limit-theorem" title="Permalink to this headline">¶</a></h2>
<p>Under certain conditions, a central limit theorem holds for the MLE,
<span class="math">\(\hat{\theta}\)</span>.</p>
<ul class="to-build simple">
<li>For infinitely large samples <span class="math">\({\bf y}\)</span>,</li>
</ul>
<div class="to-build math">
\[\hat{\theta} \sim \mathcal{N}(\theta, \mathcal{I}(\theta)^{-1}).\]</div>
<ul class="to-build simple">
<li>For large samples, <span class="math">\(\hat{\theta}\)</span> is normally distributed
<em>regardless</em> of the distribution of the data, <span class="math">\({\bf y}\)</span>.</li>
</ul>
</div>
<div class="section" id="id14">
<h2>MLE Central Limit Theorem<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><span class="math">\(\hat{\theta}\)</span> is also normally distributed for large samples
even if <span class="math">\(\mathcal{L}(\theta|{\bf y})\)</span> is some other
distribution.</li>
</ul>
<ul class="to-build simple">
<li>Hence, for large samples,</li>
</ul>
<div class="to-build math">
\[\begin{split}Var(\hat{\theta}) &amp; = \frac{1}{\mathcal{I}(\theta)} \qquad
\Rightarrow \qquad Std(\hat{\theta}) =
\frac{1}{\sqrt{\mathcal{I}(\theta)}}.\end{split}\]</div>
</div>
<div class="section" id="mle-standard-errors">
<h2>MLE Standard Errors<a class="headerlink" href="#mle-standard-errors" title="Permalink to this headline">¶</a></h2>
<p>Since we don&#8217;t know the true <span class="math">\(\theta\)</span>, we approximate</p>
<div class="math">
\[\begin{split}Std(\hat{\theta}) &amp; \approx
\frac{1}{\sqrt{\mathcal{I}(\hat{\theta})}}.\end{split}\]</div>
<ul class="to-build simple">
<li>Alternatively, to avoid computing the expectation, we could use the
approximation</li>
</ul>
<div class="to-build math">
\[\begin{split}Std(\hat{\theta}) &amp; \approx
\frac{1}{\sqrt{\widetilde{\mathcal{I}}(\hat{\theta})}}.\end{split}\]</div>
</div>
<div class="section" id="id15">
<h2>MLE Standard Errors<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>In reality, we never have an infinite sample size.</li>
</ul>
<ul class="to-build simple">
<li>For finite samples, these values are approximations of the standard
error of <span class="math">\(\hat{\theta}\)</span>.</li>
</ul>
</div>
<div class="section" id="mle-variance-example">
<h2>MLE Variance Example<a class="headerlink" href="#mle-variance-example" title="Permalink to this headline">¶</a></h2>
<p>Let&#8217;s return to the example where <span class="math">\(Y_1, \ldots, Y_n
\stackrel{i.i.d.}{\sim} \mathcal{N}(\mu, \sigma^2)\)</span>, with known
<span class="math">\(\sigma\)</span>.</p>
<ul class="to-build simple">
<li>The log likelihood is</li>
</ul>
<div class="to-build math">
\[\begin{split}\ell(\mu|{\bf y}) &amp; = -\frac{n}{2} \log(2\pi) - \frac{n}{2}
\log(\sigma^2) - \frac{1}{2 \sigma^2} \sum_{i=1}^n (y_i - \mu)^2.\end{split}\]</div>
<ul class="to-build simple">
<li>The resulting derivatives are</li>
</ul>
<div class="to-build math">
\[\begin{split}\frac{\partial \ell(\mu|{\bf y})}{\partial \mu} &amp; =
\frac{1}{\sigma^2} \sum_{i=1}^n (y_i - \mu),  \qquad
\frac{\partial^2 \ell(\mu|{\bf y})}{\partial \mu^2} =
-\frac{n}{\sigma^2}.\end{split}\]</div>
</div>
<div class="section" id="id16">
<h2>MLE Variance Example<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h2>
<p>In this case the Fisher Information is identical to the observed
Fisher Information:</p>
<div class="math">
\[\begin{split}\mathcal{I}(\mu) &amp; = -E\left[-\frac{n}{\sigma^2}\right] =
\frac{n}{\sigma^2} = \widetilde{\mathcal{I}}(\mu).\end{split}\]</div>
<ul class="to-build simple">
<li>Since <span class="math">\(\mathcal{I}(\mu)\)</span> doesn&#8217;t depend on <span class="math">\(\mu\)</span>, we
don&#8217;t need to resort to an approximation with <span class="math">\(\hat{\mu} =
\bar{{\bf y}}\)</span>.</li>
</ul>
<ul class="to-build simple">
<li>The result is</li>
</ul>
<div class="to-build math">
\[\begin{split}Std(\hat{\mu})  &amp; = \frac{1}{\sqrt{\mathcal{I}(\mu)}} =
\frac{\sigma}{\sqrt{n}}.\end{split}\]</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="resample.html" class="btn btn-neutral float-right" title="Resampling" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="heavyDist.html" class="btn btn-neutral" title="Heavy-Tailed Distributions" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2014, Eric M. Aldrich.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'Advanced Quantitative Methods',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>